<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312" />
<title>TWSVM</title>
<link rel="stylesheet" type="text/css" href="../style.css" />
</head>

<body>
<div class="logo" align="center"><a href="http://www.optimal-group.org" target="_blank"></a></div> 
<div id="container">
<p align="right">[<a href="http://www.optimal-group.org" target="_self" >Home</a>]</p> 
</br>
<h5><font face="Times New Roman" size="4"><b>TWSVM</b></font></h5>
<hr />
<p> TWSVM is a twin support vector machine for binary classification. This package provides an implementation of the TBSVM (TWSVM is a special case of TBSVM) method by Matlab code. (You could Right-Click <a href="TWSVM/TWSVM.rar">[Code]</a> , and Save, then you can download the whole matlab code.) </p>



<br />
<h5><font face="Times New Roman" size="4"><b>Reference</b></font></h5>
<hr />
<p>Yuan-Hai Shao, Chun-Hua Zhang, Xiao-Bo. Wang, Nai-Yang Deng*. Improvements on Twin Support Vector Machines[J]. <b>IEEE Transactions on Neural Networks</b>, 2011, 22(6): 962-968. </p>
<p>Yuan-Hai Shao, Nai-Yang Deng*, Zhi-Ming Yang, Wei-Jie Chen, Zhen Wang. Probabilistic outputs for twin support vector machines[J]. <b>Knowledge-Based Systems</b>, 2012, 33: 145¨C151.</p>

<br />
<h5><font face="Times New Roman" size="4"><b>Main Function</b></font></h5>
<hr />
<p>Need kernel function and SOR function.</p>

<div style="white-space:pre">
<b class="purple">function Predict_Y = TWSVM(TestX,DataTrain,FunPara)</b>
<b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TWSVM: Twin Support Vector Machine
%
% Predict_Y = TWSVM(TestX,DataTrain,FunPara)
% 
% Input:
%    TestX - Test Data matrix. Each row vector of fea is a data point.
%
%    DataTrain - Struct value in Matlab(Training data).
%                DataTrain.A: Positive input of Data matrix.
%                DataTrain.B: Negative input of Data matrix.
%
%    FunPara - Struct value in Matlab. The fields in options that can be set: 
%              c1: [0,inf] Paramter to tune the weight. 
%              c2: [0,inf] Paramter to tune the weight. 
%              c3: [0,inf] Paramter to tune the weight. 
%              c4: [0,inf] Paramter to tune the weight. 
%              kerfPara:Kernel parameters. See kernelfun.m.
%
% Output:
%    Predict_Y - Predict value of the TestX.
%
% Examples:
%    DataTrain.A = rand(50,10);
%    DataTrain.B = rand(60,10);
%    TestX=rand(20,10);
%    FunPara.c1=0.1;
%    FunPara.c2=0.1;
%    FunPara.c3=0.1;
%    FunPara.c4=0.1;
%    FunPara.kerfPara.type = 'lin';
%    Predict_Y = TWSVM(TestX,DataTrain,FunPara);
%
% Reference:
%    Y.-H. Shao, C.-H. Chun, X.-B. Wang, N.-Y. Deng.Improvements on Twin 
%    Support Vector Machines.IEEE Transactions on Neural Networks, 2011, 22
%    (6):962-968.
%
%    Version 1.0 --Apr/2013 
%
%    Written by Yuan-Hai Shao (shaoyuanhai21@163.com)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Initailization
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
%tic;
Xpos = DataTrain.A;
Xneg = DataTrain.B;
cpos = FunPara.c1;
cneg = FunPara.c2;
eps1 = FunPara.c3;
eps2 = FunPara.c4;
kerfPara = FunPara.kerfPara;
m1=size(Xpos,1);
m2=size(Xneg,1);
e1=-ones(m1,1);
e2=-ones(m2,1);
</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Compute Kernel 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
if strcmp(kerfPara.type,'lin')
    H=[Xpos,-e1];
    G=[Xneg,-e2];
else
    X=[DataTrain.A;DataTrain.B];
    H=[kernelfun(Xpos,kerfPara,X),-e1];
    G=[kernelfun(Xneg,kerfPara,X),-e2];
end
</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Compute (w1,b1) and (w2,b2)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
%%%%DTWSVM1
HH=H'*H;
HH = HH + eps1*eye(size(HH));%regularization
HHG = HH\G';
kerH1=G*HHG;
kerH1=(kerH1+kerH1')/2;
alpha=qpSOR(kerH1,0.5,cpos,0.05); %SOR
vpos=-HHG*alpha;
	
%%%%DTWSVM2
QQ=G'*G;
QQ=QQ + eps2*eye(size(QQ));%regularization
QQP=QQ\H';
kerH1=H*QQP;
kerH1=(kerH1+kerH1')/2;
gamma=qpSOR(kerH1,0.5,cneg,0.05);
vneg=QQP*gamma;
clear kerH1 H G HH HHG QQ QQP;

w1=vpos(1:(length(vpos)-1));
b1=vpos(length(vpos));
w2=vneg(1:(length(vneg)-1));
b2=vneg(length(vneg));
%toc;    
</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Predict and output
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
m=size(TestX,1);
if strcmp(kerfPara.type,'lin')
    H=TestX;
    w11=sqrt(w1'*w1);
    w22=sqrt(w2'*w2);
    y1=H*w1+b1*ones(m,1);
    y2=H*w2+b2*ones(m,1);    
else
    C=[DataTrain.A;DataTrain.B];
    H=kernelfun(TestX,kerfPara,C);
    w11=sqrt(w1'*kernelfun(X,kerfPara,C)*w1);
    w22=sqrt(w2'*kernelfun(X,kerfPara,C)*w2);
    y1=H*w1+b1*ones(m,1);
    y2=H*w2+b2*ones(m,1);
end
wp=sqrt(2+2*w1'*w2/(w11*w22));
wm=sqrt(2-2*w1'*w2/(w11*w22));
clear H; clear C;
 
m1=y1/w11;
m2=y2/w22;
MP=(m1+m2)/wp;
MN=(m1-m2)/wm;
mind=min(abs(MP),abs(MN));
maxd=max(abs(MP),abs(MN));
Predict_Y = sign(abs(m2)-abs(m1));
</b>

</div>


<h5><a name="C1"><font face="Times New Roman" size="4.5">Contacts</font></a></font face="Times New Roman" size="4.5"></a> </h5>
<hr />

<br />
Any question or advice please email to shaoyuanhai21@163.com.

<p />

<hr />
</p><ul><li>Last updated: April 5, 2013


<br />
<br />







  <div class="rssfeed">
    
 </div>

</div>

</div>

</body>
</html>
