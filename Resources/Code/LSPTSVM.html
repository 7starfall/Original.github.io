<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312" />
<title>LSPTSVM</title>
<link rel="stylesheet" type="text/css" href="../style.css" />
</head>

<body>
<div class="logo" align="center"><a href="http://www.optimal-group.org" target="_blank"></a></div> 
<div id="container">
<p align="right">[<a href="http://www.optimal-group.org" target="_self" >Home</a>]</p> 
</br>
<h5><font face="Times New Roman" size="4"><b>LSPTSVM</b></font></h5>
<hr />
<p> A Matlab code for least squares recursive projection twin support vector machine. (You could Right-Click <a href="./LSPTSVM/LSPTSVM.rar">[Code]</a> , and Save, then you can download the whole matlab code.) </p>



<br />
<h5><font face="Times New Roman" size="4"><b>Reference</b></font></h5>
<hr />
<p>Yuan-Hai Shao, Nai-Yang Deng*, Zhi-Min Yang. Least squares recursive projection twin support vector machine for classification[J]. <b>Pattern Recognition</b>, 2012, 45(6): 2299-2307. </p>
<p>Yuan-Hai Shao, Zhen Wang, Wei-Jie Chen, Nai-Yang Deng*. A regularization for the projection twin support vector machine[J]. <b>Knowledge-Based Systems</b>, 2013, 37: 203¨C210. </p>

<br />
<h5><font face="Times New Roman" size="4"><b>Main Function</b></font></h5>
<hr />


<div style="white-space:pre">
<b class="purple">function Predict_Y = LSPTSVM(TestX,DataTrain,FunPara)</b>
<b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LSPTSVM: Least squares recursive projection twin support vector machine
%
% Predict_Y = LSPTSVM(TestX,DataTrain,FunPara)
% 
% Input:
%    TestX - Test Data matrix. Each row vector of fea is a data point.
%
%    DataTrain - Struct value in Matlab(Training data).
%                DataTrain.A: Positive input of Data matrix.
%                DataTrain.B: Negative input of Data matrix.
%
%    FunPara - Struct value in Matlab. The fields in options that can be set: 
%              c1: [0,inf] Paramter to tune the weight. 
%              c2: [0,inf] Paramter to tune the weight. 
%              c3: [0,inf] Paramter to tune the weight. 
%              c4: [0,inf] Paramter to tune the weight. 
%
% Output:
%    Predict_Y - Predict value of the TestX.
%
% Examples:
%    DataTrain.A = rand(50,10);
%    DataTrain.B = rand(60,10);
%    TestX=rand(20,10);
%    FunPara.c1=0.1;
%    FunPara.c2=0.1;
%    FunPara.c3=0.1;
%    FunPara.c4=0.1;
%    Predict_Y = LSPTSVM(TestX,DataTrain,FunPara);
%
% Reference:
%    Y.-H. Shao, N.-Y. Deng, Z.-M. Yang.Least squares recursive projection 
%    twin support vector machine for classification .Pattern Recognition,2012,
%    45(6): 2299-2307.
%
%    Version 1.0 --Apr/2011 
%    Written by Yuan-Hai Shao (shaoyuanhai21@163.com)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Initailization
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
%tic;
inputA = DataTrain.A;
inputB = DataTrain.B;
c1 = FunPara.c1;
c2 = FunPara.c2;
c3 = FunPara.c3;
c4 = FunPara.c4;
[m1,n1]=size(inputA);
m2=size(inputB,1);
e1=ones(m1,1);
e2=ones(m2,1);
</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Compute w1 and w2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
center1=1/m1*sum(inputA(:,:));
center2=1/m2*sum(inputB(:,:));
S1=(inputA(1,:)-center1)'*(inputA(1,:)-center1);
S2=(inputB(1,:)-center2)'*(inputB(1,:)-center2);
for i=2:m1
    S1=S1+(inputA(i,:)-center1)'*(inputA(i,:)-center1);
end
for i=2:m2
    S2=S2+(inputB(i,:)-center2)'*(inputB(i,:)-center2);
end
w1=(S1/c1+(inputB-1/m1*e2*e1'*inputA)'*(inputB-1/m1*e2*e1'*inputA)+c3/c1*eye(n1,n1))\((inputB-1/m1*e2*e1'*inputA)'*e2);
w2=-(S2/c2+(inputA-1/m2*e1*e2'*inputB)'*(inputA-1/m2*e1*e2'*inputB)+c4/c2*eye(n1,n1))\((inputA-1/m2*e1*e2'*inputB)'*e1);
W1=w1;
W2=w2;
</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%While multiple orthogonal recursive projection
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
% mop=0;
% while mop>0
%         for i=1:m1
%             inputA(i,:)=inputA(i,:)-(w1*inputA(i,:)*w1)';
%         end
%         for i=1:m2
%             inputB(i,:)=inputB(i,:)-(w2*inputB(i,:)*w2)';
%         end
%         center1=1/m1*sum(inputA(:,:));
%         center2=1/m2*sum(inputB(:,:));
%         S1=(inputA(1,:)-center1)'*(inputA(1,:)-center1);
%         S2=(inputB(1,:)-center2)'*(inputB(1,:)-center2);
%         for i=2:m1
%             S1=S1+(inputA(i,:)-center1)'*(inputA(i,:)-center1);
%         end
%         for i=2:m2
%             S2=S2+(inputB(i,:)-center2)'*(inputB(i,:)-center2);
%         end
%         S1=S1+eps*eye(n1,n1);
%         S2=S2+eps*eye(n1,n1);
%         w1=(S1/c1+(inputB-1/m1*e2*e1'*inputA)'*(inputB-1/m1*e2*e1'*inputA)+c3/c1*eye(n1,n1))\((inputB-1/m1*e2*e1'*inputA)'*e2);
%         w2=-(S2/c2+(inputA-1/m2*e1*e2'*inputB)'*(inputA-1/m2*e1*e2'*inputB)+c4/c2*eye(n1,n1))\((inputA-1/m2*e1*e2'*inputB)'*e1);
%         W1=[W1,w1];
%         W2=[W2,w2];
%     mop=mop-1;
% end
% toc
</b><b class="green">
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Predict and output
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</b><b class="code">
for i=1:m
Y11(i,:)=TestX(i,:)*W1-center1*W1;
Y22(i,:)=TestX(i,:)*W2-center2*W2; 
if norm(Y11(i,:)) <= norm(Y22(i,:))
Predict_Y(i,:)=1;
else
Predict_Y(i,:)=-1;
end
end
</b>

</div>

<h5><a name="C1"><font face="Times New Roman" size="4.5">Contacts</font></a></font face="Times New Roman" size="4.5"></a> </h5>
<hr />

<br />
Any question or advice please email to shaoyuanhai21@163.com.

<p />

<hr />
</p><ul><li>Last updated: Jun 5, 2013


<br />
<br />







  <div class="rssfeed">
    
 </div>

</div>

</div>

</body>
</html>